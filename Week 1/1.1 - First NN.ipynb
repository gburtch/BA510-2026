{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsrm5E3ZJXuYGWIxjNEmg1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gburtch/BA510-2026/blob/main/Week%201/1.1%20-%20First%20NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Our First Neural Network**"
      ],
      "metadata": {
        "id": "YUjgaB_j7X8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to import the MNIST dataset, and train our first neural network! Don't worry too much about what the arguments / parameters are that we are specifying when we get to the neural net piece; we will go over those elements subsequently."
      ],
      "metadata": {
        "id": "zWXpAQ2_7b6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Data and Library Imports*"
      ],
      "metadata": {
        "id": "7RIfyYlww1pY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Vrwog1mqWxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab021d2c-7e09-4be0-ef12-947f5968f623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image as im\n",
        "from IPython.display import Image\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 60,000 images, and each is made up of 28x28 = 784 pixels."
      ],
      "metadata": {
        "id": "rxBqJlVyrQ57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "J6X7aPK9qsVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pixels take on values between 0 and 255."
      ],
      "metadata": {
        "id": "3_PQp4ostcG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_vector = np.reshape(train_images,-1)\n",
        "\n",
        "plt.hist(train_vector, bins=256)\n",
        "plt.title=\"Histogram of Pixel Values\"\n",
        "plt.show()\n",
        "\n",
        "pd.DataFrame(train_vector).describe()"
      ],
      "metadata": {
        "id": "wTOjf86Xrb0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what one of these arrays looks like as a picture..."
      ],
      "metadata": {
        "id": "dCKHKQBUwvMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_images[0],cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0daH-CVb6e0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every image array has a single label associated with it, an integer between 0 and 9."
      ],
      "metadata": {
        "id": "gSzY08epxipn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(train_labels,bins=10)\n",
        "plt.show()\n",
        "\n",
        "pd.DataFrame(np.reshape(train_labels,-1)).describe()"
      ],
      "metadata": {
        "id": "cuxMqTdCxk6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Train a Neural Net*"
      ],
      "metadata": {
        "id": "H0k50psnxYyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will instantiate our first neural network. We begin by loading the Keras library, specifying the structure of each layer in the network, and indicating what activation function we will use in each layer."
      ],
      "metadata": {
        "id": "UNQVA1C6ynPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "4iHsWSGCyvIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will indicate some configuration parameters. In particular, what optimization algorithm to use (RMSProp), what loss function to use (multinomial cross-entropy), and what metric to optimize on (accuracy)."
      ],
      "metadata": {
        "id": "h60jPNhYzmLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "2DClkQwazlbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to reformat the data. We need to convert the values into floats (fractional values), scaled to the 0-1 range. Further, we need to reshape each of the 28x28 arrays into individual vectors of length 784."
      ],
      "metadata": {
        "id": "kUOPS9KNz75c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(len(train_images),28*28)\n",
        "train_images = train_images.astype(float)/255\n",
        "test_images = test_images.reshape(len(test_images),28*28)\n",
        "test_images = test_images.astype(float)/255\n",
        "print(train_images.shape)\n",
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmKikEfU0PCB",
        "outputId": "881655b3-fb8a-49c9-8402-0ba7fdac756b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can 'fit' the model to the training data. We will come back to what these arguments mean, but batch_size refers to the number of observations that are used in a given iteration of the optimization, an epoch refers to a complete run through of iterations such that the entire sample of training data is 'covered' (60000 / 128 batches per epoch in this case). Thus, 5 epochs means that we repeat the optimization procedure over the whole dataset 5 times.\n",
        "\n"
      ],
      "metadata": {
        "id": "bimI9luT1K1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "id": "BCVHftM01Max"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have fit the model, we can use it to generate productions on the holdout data. Note that the output is comprised of 10 class labels. The predictions are probabilistic, and sum to 1. So, of the resulting 10 predictions, the index for the highest value is the most probable class.  "
      ],
      "metadata": {
        "id": "QjzcJN7z10c7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)\n",
        "predictions[1:5]"
      ],
      "metadata": {
        "id": "KsI-swBI13d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it's very accurate!"
      ],
      "metadata": {
        "id": "DyS870BB3mEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(test_labels,np.argmax(predictions,axis=1))\n",
        "print(result[1:10])"
      ],
      "metadata": {
        "id": "8p1ncqzh2UrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the Keras-inherent functions to return accuracy and loss pretty easily. Notice that the accuracy of predictions in the test data is lower than that in the training data."
      ],
      "metadata": {
        "id": "0U_r61c83pVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"test_acc: \",test_acc)\n",
        "test_acc: 0.9785"
      ],
      "metadata": {
        "id": "g_8iLoWS3tVA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}